# üìö Plan de R√©vision ‚Äì Master Intelligence Artificielle (√©t√©)

## üß† Objectifs g√©n√©raux

- Consolider les bases th√©oriques en **probabilit√©s** et **optimisation**
- Pratiquer les m√©thodes de **simulation** et impl√©menter des algorithmes
- R√©diger une **fiche de r√©vision compl√®te en probabilit√©s**
- √ätre pr√™t pour les cours/examens en IA, stats, simulation, etc.

---

## ‚úÖ √Ä r√©viser par th√®me

### üîµ Probabilit√©s

#### Variables al√©atoires (VA)
- D√©finition d‚Äôune VA, loi de probabilit√©
- Esp√©rance, variance, moments
- Loi discr√®te vs continue
- Lois classiques : Bernoulli, Binomiale, Poisson, G√©om√©trique, Exponentielle, Normale

#### Loi des Grands Nombres
- LLN faible et fort (d√©finitions, intuition)
- D√©monstrations simples
- Application √† la convergence de Monte Carlo

#### Th√©or√®me Central Limite
- TCL classique (i.i.d., loi normale)
- Version multivari√©e
- Applications √† l‚Äôestimation

#### M√©thodes de Monte Carlo
- Estimation d‚Äôint√©grales
- Approximation de constantes
- Analyse de l‚Äôerreur (biais, variance)
- Importance du TCL

#### In√©galit√©s de concentration *(facultatif mais utile)*
- Chebyshev, Hoeffding
- Bahadur-Rao, Cram√©r-Chernoff (√† lire seulement si temps)

#### Cha√Ænes de Markov
- D√©finition, transition, matrice
- Espaces d‚Äô√©tats finis et continus
- Simulation d‚Äôune cha√Æne
- Convergence vers l‚Äôinvariant

#### TD Universit√©
- Faire tous les exercices du TD
- Ajouter dans la fiche les d√©finitions/manips utiles

---

### üü† Optimisation

#### Probl√®mes sans contraintes
- Descente de gradient, taux de convergence
- M√©thode de Newton
- Propri√©t√©s des fonctions (Lipschitz, diff√©rentiabilit√©)

#### Probl√®mes avec contraintes
- M√©thode des multiplicateurs de Lagrange
- Conditions de Karush-Kuhn-Tucker (KKT)
- M√©thode de projection sur un convexe

#### Convexit√© et topologie
- Ensemble convexe, fonction convexe
- Fermeture, compacit√©, coercivit√©
- Lien entre topologie et existence d‚Äôun minimum

#### Programmation d‚Äôalgorithmes
- Gradient sur fonction quadratique
- Newton avec matrice Hessienne
- Optimisation avec contraintes simples

---

### üü¢ Simulation (cours de 6 ECTS)

#### Simulations de VA et Monte Carlo
- M√©thode de la fonction de r√©partition inverse
- M√©thode du rejet
- M√©thode de Box-Muller (g√©n√©ration loi normale)
- Monte Carlo brut (avec erreur)

#### R√©√©chantillonnage
- Bootstrap (intervalles de confiance)
- Jackknife
- Validation crois√©e pour estimation

#### Simulation dans mod√®le gaussien
- Vecteurs gaussiens
- Conditionnement gaussien
- R√©gression lin√©aire gaussienne
- Filtrage de Kalman
- TCL multidimensionnel

#### Grandes d√©viations *(bonus)*
- In√©galit√©s : Chebyshev, Hoeffding, Cram√©r

#### Cha√Ænes de Markov
- Simulations d‚Äô√©tats
- Estimations de transition
- Illustration de la convergence

---

## üìÖ Planning hebdomadaire (8 semaines)

| Semaine | Th√®mes | Objectifs d√©taill√©s |
|--------|--------|----------------------|
| **S1** | Probas (VA, LLN), Opti (sans contraintes), Simu (Monte Carlo brut) |<ul><li>R√©diger fiche : d√©finitions VA, esp√©rance, variance</li><li>Faire d√©mo LLN + exos</li><li>Impl√©menter Monte Carlo brut (int√©grale simple)</li><li>R√©viser gradient descente (algorithme + code)</li></ul>|
| **S2** | TCL, Monte Carlo, Opti (avec contraintes), Simu (m√©thodes inversion, rejet) |<ul><li>Fiche : TCL, preuve, applications</li><li>Impl√©menter m√©thode de rejet</li><li>Faire 1 exo Lagrange</li><li>Code : Newton 1D + gradient 2D</li></ul>|
| **S3** | TD Toul, Convexit√©/topologie, Simu (bootstrap, jackknife) |<ul><li>Faire tous les exos du TD Toul</li><li>Ajouter parties √† la fiche (r√©sum√©s + techniques vues dans les exos)</li><li>Rappels topologie/convexit√© (th√©orie + exemples)</li><li>Bootstrap sur estimation d‚Äôune moyenne</li></ul>|
| **S4** | R√©daction fiche + exos, Opti (m√©thodes num√©riques), Simu (Box-Muller, gaussienne) |<ul><li>Compl√©ter fiche (focus loi normale, exemples)</li><li>Impl√©menter Box-Muller + visualisation</li><li>Exercices optimisation avec descente</li></ul>|
| **S5** | In√©galit√©s de concentration, Opti (exos complexes), Simu (conditionnement, r√©gression) |<ul><li>Fiche : Chebyshev + Hoeffding</li><li>Exemple simple r√©gression gaussienne</li><li>Simuler le conditionnement</li></ul>|
| **S6** | Cha√Ænes de Markov (introduction), Kalman, Simu |<ul><li>Simulation d‚Äôune cha√Æne de Markov finie</li><li>Impl√©menter Kalman simple</li><li>Faire point sur convergence + invariante</li></ul>|
| **S7** | Relecture, exercices transverses, fiche optimisation |<ul><li>Finaliser fiche probas</li><li>R√©diger fiche optim</li><li>Refaire exos simul + Markov</li></ul>|
| **S8** | R√©visions g√©n√©rales, mini-projet |<ul><li>Revoir toutes les m√©thodes cod√©es</li><li>Corriger les fiches</li><li>Pr√©parer projet simulation s‚Äôil y en a un</li></ul>|

---

## üõ†Ô∏è Conseils pratiques

- G√©rer ta fiche de probas en **LaTeX** ou **Markdown** (structure claire)
- Conserver un dossier `simu/` pour tous les scripts de simulation
- Si besoin : cr√©e un d√©p√¥t Git (`probas-ai`) pour versionner ton travail
- Une fois par semaine, **relire tes notes de simulation** comme si tu devais les enseigner

---

## üì¶ Bonus si temps

- Lire sur **m√©thodes MCMC** (Metropolis-Hastings, Gibbs)
- Regarder un cas r√©el d'application du **filtrage de Kalman**
- Impl√©menter un **simulateur simple de cha√Æne de Markov cach√©e**
