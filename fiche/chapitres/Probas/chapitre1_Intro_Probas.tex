\chapter{Espaces Probabilisés et Variables Aléatoires}

\justify

\setlength{\parindent}{0pt}
\renewcommand{\labelitemi}{\textbullet} % Utiliser des points noirs (•)

% ==================================================================================================================================
% Introduction 

% TODO : 


% ==================================================================================================================================
% Espaces Probabilisés et Mesures 

\section{Espaces Probabilisés, Mesures et Variables Aléatoires}

\subsection{Univers}

Introduisons les concepts fondamentaux des probabilités, les univers et les espaces probabilisés. 

\begin{definition}[Univers]
    On appelle univers $\Omega$ pour une expérience aléatoire, l'ensemble de toutes les issues (situations finales) possibles 
    de cette expérience aléatoire. Chaque élément $ \omega \in \Omega$ représente une \textbf{issue} de cette expérience aléatoire.  
\end{definition}

\begin{example}
    \begin{itemize}
        \item Pour une expérience aléatoire de lancer de dé, il existe 6 issues possibles correspondant aux 6 faces du dé. 
        On a donc $\Omega = \{1, 2, 3, 4, 5, 6\}$. 
        \item Si on pioche un boule dans une urne contenant une boule rouge et deux boules noires, on a 
        $ \Omega = \{\text{rouge}, \text{noir}\}$. 
    \end{itemize}
\end{example}

A partir d'un univers, on peut définir la notion d'espace probabilisé. Plus complexe, la définition nécessaire les prérequis 
du cours d'intégration et de théorie de la mesure. 

\begin{definition}[Espace Probabilisé]
    Un espace probabilisé est un \textbf{triplet} $ (\Omega, \mathcal{F}, \myP)$ où :
    \begin{itemize}
        \item $\Omega$ est un univers. 
        \item $ \mathcal{F}$ est une tribu ($\sigma$-algèbre) sur $ \Omega$. 
        \item $ \myP$ est une mesure de probabilité sur $ \mathcal{F}$ (voir plus loin). 
    \end{itemize}
\end{definition}



\subsection{Évènements, Issues et Mesure de Probabilité }

\begin{definition}[Évènement]
    Soit $\Omega$ un univers. On définit un évènement de $\Omega$ comme un sous-ensemble $A \subseteq \Omega$. 
\end{definition}

\begin{remark}
    Comme définit au début, les \textbf{issues} $ \omega \in \Omega$ correspondent à des résultats élémentaires de l'expérience 
    aléatoire, à ne pas confondre avec les évènements. 
    Dans notre expérience de lancer de dé, $\{2\} \in \Omega$ est \textbf{l'issue} correspondant à "obtenir un 2" et 
    $A = \{1,2\} \subset \Omega$ est \textbf{l'évènement} correspondant à "le résultat est inférieur ou égal à 2". 
\end{remark}

Par construction, $ \mathcal{F}$ contient donc tous les évènements et issues possibles de l'expérience aléatoire. 
Elle est dont "plus complète" que $\Omega$, on retrouve les propriétés des espaces mesurables, vus en intégration en Licence. 

\begin{definition}[Mesure de Probabilité]
    Soit un espace probabilisé $(\Omega, \mathcal{F}, \myP)$. Une mesure de probabilité $ \myP$ 
    sur $ \mathcal{F}$ est une mesure (au sens de la théorie de la mesure) qui vérifie : 
    \begin{enumerate}
        \item $ \myP : \mathcal{F} \longrightarrow [0,1]$
        \item $ \myP(\Omega) = 1$ 
    \end{enumerate}
\end{definition}

\begin{remark}[Rappel : Mesure]
    Une fonction $ \mu : (X, \mathcal{B}) \longrightarrow \overline{\R_+}$ telle que : 
    \begin{enumerate}
        \item $ \mu(\emptyset) = 0 $ 
        \item \textbf{(Sigma-additivité)} : $ \forall (A_n)_{n \in \N}$ suite de parties mesures \textbf{deux à deux disjointes}, on ait : 
            \[ \mu \left( \bigcup_{n \in \N} A_n \right) = \sum_{n \in \N} \mu(A_n) \]
        est appelée mesure sur l'espace $(X, \mathcal{B}, \mu)$ alors appelé \textbf{espace mesuré}. 
    \end{enumerate}
\end{remark}



% ==================================================================================================================================
% Variables Aléatoires


\section{Variables Aléatoires}

\subsection{Définition et Loi}

Pour pouvoir quantifier des calculs de probabilités ou ce que nous appellerons plus tard des lois, nous devons définir 
les variables aléatoires. 

\begin{definition}[Variable Aléatoire]
    Une variable aléatoire est une fonction mesurable qui associe une valeur numérique à chaque issue d'un espace probabilisé. 

    \vspace{0.5cm}

    Plus formellement, soit $(\Omega, \mathcal{F}, \myP)$ un espace probabilisé et $E$ un ensemble. 
    Une \emph{variable aléatoire $X$ sur $\Omega$ à valeurs dans $E$} est une fonction mesurable $X : \Omega \longrightarrow E$. 
    Dans le cas où $E = \R$ on parlera de \emph{variable aléatoire réelle}. 
\end{definition}

La mesurabilité d'une variable aléatoire permet donc garantir que les évènements associés aux valeurs de la variable 
aléatoire sont bien mesurables par la mesure de probabilité. 

\begin{definition}[Support]
    Soit $X$ une variable aléatoire sur un univers $\Omega$ dans $\R$. 
    On appelle \emph{support de $X$} l'image directe de $\Omega$ par $X$, autrement dit, 
    l'ensemble $X(\Omega) = \{X(\omega) \; | \; \omega \in \Omega\}$. Il correspond à l'ensemble 
    des valeurs prises par $X$.  
\end{definition}

Le support d'une variable aléatoire $X : \Omega \longrightarrow E$ est un ensemble fini car $\Omega$ est 
lui-même un ensemble fini par hypothèse.

\begin{proposition}
    La définition de variable alétoire comme fonction mesurable nous permet de définir formellement 
    le notion d'évènement d'une expérience aléatoire. En effet, considérons une variable aléatoire $X : \Omega \longrightarrow E$ 
    définie sur un espace probabilisé $(\Omega, \mathcal{F}, \myP)$ et soit $ \mathcal{B}$ une tribu sur $E$. 

    Puisque $X$ est une fonction mesurable, on sait que : 
        \[ \forall B \in \mathcal{B}, X^{-1}(B) \in \mathcal{F} \] 
    \emph{(i.e toute préimage d'un borélien est un borélien)} 
    On va donc définir un évènement d'une expérience aléatoire comme la préimage d'un élément de $ \mathcal{B}$. 
    D'où la définition suivante...
\end{proposition}

\begin{definition}[Evènement d'une expérience aléatoire]
    Soit $X$ une variable aléatoire définie sur un univers $\Omega$ à valeurs dans $E$. 
    On appelle évènement $[X = x]$ de l'expérience aléatoire l'ensemble des issues possibles 
    correspondant à cet évènement $x \in E$ . 
    Autrement dit :
        \[ [X = x] = \{w \in \Omega \; | \; X(\omega) = x\} = X^{-1}(x) \] 
    Plus généralement soit $A \in \mathcal{B}$ une tribu sur $E$, 
        \[ [X \in A] = \{ \omega \in \Omega \; | \; X(\omega) \in A \} = X^{-1}(A) \] 
\end{definition}

\begin{definition}[Loi]
    Soit $X$ une variable aléatoire. On appelle loi de $X$ la donnée de toutes les probabilités $ \myP(X = x)$ pour 
    tout $x \in X(\Omega)$.  
\end{definition}

Pour donner la loi d'une variable aléatoire, il faut d'abord déterminer le support de la variable aléatoire puis en suite 
calculer la probabilité de chaque issue. 
On note le résultat dans un tableau pour plus de praticité. 

\begin{example}
    Soit l'exprérience aléatoire du lancer d'un dé à 6 faces non truqué. On a :
        \[ \Omega = \{1,2,3,4,5,6\} \]
    Nous nous trouvons dans une situation d'équiprobabilité d'où :
        \[ \forall x \in X(\Omega), \quad \myP(X = x) = \frac{1}{6} \]
    D'où le tableau suivant :
    \begin{center}
        \begin{tabular}{c|c|c|c|c|c|c}
            $\Omega$ & 1 & 2 & 3 & 4 & 5 & 6 \\
            \hline 
            $ \myP(X = x)$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ \\ 
        \end{tabular}
    \end{center}  
\end{example}

\subsection{Variables Discrètes et Continues}

Selon la nature de l'espérience aléatoire et de l'univers choisis, on distingue deux grands types de variables aléatoires : 
les variables aléatoires \textbf{discrètes} et \textbf{continues}. Cette distinction est fondamentale car elle 
caractérise la façon dont on exprime et calcule ensuite les probabilités.

\begin{definition}[Variable aléatoire discrète]
    Une variable aléatoire $X$ définie sur un espace probabilisé $(\Omega, \mathcal{F}, \myP)$ est dite 
    \textbf{discrète} si l'ensemble de ses valeurs possibles $X(\Omega)$ est un ensemble \textbf{fini ou dénombrable}. 
    Dans ce cas, la loi de probabilité de $X$ est donnée par une fonction de masse et les probabilités 
    s'expriment comme des sommes. 
\end{definition}

\begin{example}
    Le résultat d'un lancer de dé est une variable aléatoire discrète. 
    Par exemple, si $X$ désigne le résultat d’un lancer de dé, alors $X(\Omega) = \{1,2,3,4,5,6\}$.
\end{example}

\begin{definition}[Variable aléatoire continue]
    Une variable aléatoire $X$ est dite \textbf{continue} si elle peut prendre une infinité non dénombrable de valeurs, typiquement un intervalle de $\R$. 
    Dans ce cas, il n'existe pas de fonction de masse mais une \textbf{densité de probabilité}, et les probabilités s'expriment 
    par des \textbf{intégrales}.
\end{definition}


\begin{example}
    Le temps d'attente avant un événement (modélisé par une loi exponentielle), ou la taille d'une personne (loi normale), 
    sont des variables continues. Si $X$ est la taille d’un individu, alors $X(\Omega) \subseteq \R$ est un intervalle de réels.
\end{example}

\begin{remark}
    La distinction entre lois discrètes et lois continues repose donc sur la nature de la mesure de probabilité utilisée :
    \begin{itemize}
        \item \textbf{Mesure de comptage} (ou somme de Dirac) $\Rightarrow$ lois discrètes.
        \item \textbf{Mesure de Lebesgue} (avec densité) $\Rightarrow$ lois continues.
    \end{itemize}
\end{remark}

Nous allons maintenant étudier les deux grands types de lois de probabilité selon la nature de la variable aléatoire : 

\begin{itemize}
    \item Dans le cas discret : lois binomiale, géométrique, de Poisson...
    \item Dans le cas continu : loi uniforme, loi exponentielle, loi normale...
\end{itemize}


% ==================================================================================================================================
% Indépendance de Variables aléatoires


\section{Indépendance de variables aléatoires}

% TODO : fill-in 